{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos las librerias necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sn\n",
    "import ast\n",
    "import json\n",
    "import nltk\n",
    "from textblob import*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will carry out a standardized process for each dataset:\n",
    "\n",
    "*  JSON Import: We begin by loading the data from the corresponding JSON file.\n",
    "\n",
    "*  Exploratory Analysis: We conduct an initial analysis of the data to understand its structure and content.\n",
    "\n",
    "*  Removal of Unnecessary Columns: We identify columns that won't contribute relevant information to our analysis and remove them from the dataset.\n",
    "\n",
    "*  Format Adjustment: We ensure that the format of the remaining columns is suitable for our analysis. This may involve data type conversion or format normalization.\n",
    "\n",
    "*  Detection and Handling of Duplicates and Null Values: We identify duplicate records and manage null values in the dataset.\n",
    "\n",
    "*  This standardized process will enable us to efficiently prepare the data for subsequent analysis.\n",
    "\n",
    "*  Transform each dataset for the optimal processing of each endpoint\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the JSON files\n",
    "\n",
    "# List to store JSON dictionaries from each line\n",
    "data_list = []\n",
    "\n",
    "# JSON file path\n",
    "file_path = 'Data/australian_user_reviews.json'\n",
    "\n",
    "# Open the file and process each line\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        try:\n",
    "            # Use ast.literal_eval to convert the line into a dictionary\n",
    "            json_data = ast.literal_eval(line)\n",
    "            data_list.append(json_data)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error in line: {line}\")\n",
    "            continue\n",
    "\n",
    "# Create a DataFrame from the list of dictionaries\n",
    "df_user_reviews = pd.DataFrame(data_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpieza y Normalizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_reviews = pd.json_normalize(df_user_reviews.to_dict('records'), 'reviews', ['user_id', 'user_url'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agregacion de la columna de sentyment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\joaqu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#use lib nltk with vader_lexicon and sentiment for transform reviews in score_reviews\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "#Initialize the sentiment analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "#Function to assign values according to the scale\n",
    "def get_sentiment_score(text):\n",
    "    if pd.isnull(text) or text == '':\n",
    "        return 1  # Return neutral if it is empty or NaN\n",
    "    elif isinstance(text, str):\n",
    "        sentiment = sia.polarity_scores(text)\n",
    "        compound_score = sentiment['compound']\n",
    "        if compound_score >= -0.05:\n",
    "            return 2  # Good score\n",
    "        elif compound_score <= -0.05:\n",
    "            return 0  # Bad score\n",
    "        else:\n",
    "            return 1\n",
    "    else:\n",
    "        return 1  # Return neutral for non-string values\n",
    "\n",
    "\n",
    "#Convert column 'review' to str\n",
    "df_user_reviews['review'] = df_user_reviews['review'].astype(str)\n",
    "\n",
    "#apply function get_sentiment_score to column 'review'\n",
    "df_user_reviews['sentiment_analysis'] = df_user_reviews['review'].apply(get_sentiment_score)\n",
    "\n",
    "#Eliminar la columna review ya que con la de sentiment_score no la necesitamos\n",
    "df_user_reviews = df_user_reviews.drop(columns=['review', 'funny', 'last_edited', 'helpful', 'user_url'], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a function to remove the word \"Posted\" from a string\n",
    "def remove_posted_prefix(string):\n",
    "    return string.replace(\"Posted\", \"\")\n",
    "\n",
    "# Apply the 'remove_posted_prefix' function to the 'posted' column to clean the data\n",
    "df_user_reviews[\"posted\"] = df_user_reviews[\"posted\"].apply(remove_posted_prefix)\n",
    "\n",
    "# Filter the DataFrame to keep only the rows containing a comma in the 'posted' column\n",
    "df_user_reviews = df_user_reviews[df_user_reviews[\"posted\"].str.contains(\",\")]\n",
    "\n",
    "# Create a new 'year' column that extracts the year from the 'posted' column\n",
    "df_user_reviews[\"year\"] = df_user_reviews[\"posted\"].str.split(\", \").str[-1].str[:4]\n",
    "\n",
    "# Remove the original 'posted' column as we have extracted the relevant information\n",
    "df_user_reviews = df_user_reviews.drop(columns=['posted'], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_reviews['item_id'] = df_user_reviews['item_id'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nulos y Duplicados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove rows with missing values in the 'item_id' column\n",
    "df_user_reviews = df_user_reviews.dropna(subset=['item_id'])\n",
    "\n",
    "# Remove rows with missing values in the 'recommend' column\n",
    "df_user_reviews = df_user_reviews.dropna(subset=['recommend'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "688"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user_reviews.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_reviews = df_user_reviews.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item_id               0\n",
       "recommend             0\n",
       "user_id               0\n",
       "sentiment_analysis    0\n",
       "year                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user_reviews.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>recommend</th>\n",
       "      <th>user_id</th>\n",
       "      <th>sentiment_analysis</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1250</td>\n",
       "      <td>True</td>\n",
       "      <td>76561197970982479</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22200</td>\n",
       "      <td>True</td>\n",
       "      <td>76561197970982479</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43110</td>\n",
       "      <td>True</td>\n",
       "      <td>76561197970982479</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>251610</td>\n",
       "      <td>True</td>\n",
       "      <td>js41637</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>227300</td>\n",
       "      <td>True</td>\n",
       "      <td>js41637</td>\n",
       "      <td>2</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59252</th>\n",
       "      <td>730</td>\n",
       "      <td>True</td>\n",
       "      <td>wayfeng</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59255</th>\n",
       "      <td>253980</td>\n",
       "      <td>True</td>\n",
       "      <td>76561198251004808</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59265</th>\n",
       "      <td>730</td>\n",
       "      <td>True</td>\n",
       "      <td>72947282842</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59267</th>\n",
       "      <td>730</td>\n",
       "      <td>True</td>\n",
       "      <td>ApxLGhost</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59276</th>\n",
       "      <td>369200</td>\n",
       "      <td>True</td>\n",
       "      <td>76561198267374962</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48498 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       item_id  recommend            user_id  sentiment_analysis  year\n",
       "0         1250       True  76561197970982479                   2  2011\n",
       "1        22200       True  76561197970982479                   2  2011\n",
       "2        43110       True  76561197970982479                   2  2011\n",
       "3       251610       True            js41637                   2  2014\n",
       "4       227300       True            js41637                   2  2013\n",
       "...        ...        ...                ...                 ...   ...\n",
       "59252      730       True            wayfeng                   2  2015\n",
       "59255   253980       True  76561198251004808                   2  2015\n",
       "59265      730       True        72947282842                   0  2015\n",
       "59267      730       True          ApxLGhost                   2  2015\n",
       "59276   369200       True  76561198267374962                   2  2015\n",
       "\n",
       "[48498 rows x 5 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exportar el dataframe a parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_reviews.to_parquet('Data/user_reviews.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store JSON dictionaries from each line\n",
    "data_list = []\n",
    "\n",
    "# JSON file path\n",
    "file_path = 'Data/australian_users_items.json'\n",
    "\n",
    "# Open the file and process each line\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        try:\n",
    "            # Use ast.literal_eval to convert the line into a dictionary\n",
    "            json_data = ast.literal_eval(line)\n",
    "            data_list.append(json_data)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error in line: {line}\")\n",
    "            continue\n",
    "\n",
    "# Create a DataFrame from the list of dictionaries\n",
    "df_user_items = pd.DataFrame(data_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza y Normalizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use json_normalize to extract nested information from the 'items' column\n",
    "\n",
    "df_user_items = pd.json_normalize(\n",
    "    df_user_items.to_dict('records'),  # Convert the DataFrame into a list of dictionary-like records\n",
    "    'items',                      # Name of the column with nested data\n",
    "    ['user_id', 'items_count', 'steam_id', 'user_url']  # Additional columns to be retained\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We drop useless columns\n",
    "df_user_items = df_user_items.drop(columns=['playtime_2weeks', 'item_name', 'items_count', 'steam_id', 'user_url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns you want to convert to the integer data type\n",
    "columns_to_convert = ['item_id', 'playtime_forever']\n",
    "\n",
    "# Iterate through the columns and convert them to integers, handling errors\n",
    "for column in columns_to_convert:\n",
    "    df_user_items[column] = pd.to_numeric(df_user_items[column], errors='coerce')\n",
    "\n",
    "# Now, invalid values will be set as NaN in those columns\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicados y Nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59117"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user_items.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_items = df_user_items.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item_id             0\n",
       "playtime_forever    0\n",
       "user_id             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user_items.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_items = df_user_items.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exportar el dataframe  parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_items.to_parquet('Data/user_items.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file line by line and load each line as a JSON object\n",
    "with open('Data\\output_steam_games.json', 'r', encoding='utf-8') as file:\n",
    "    data = [json.loads(line) for line in file]\n",
    "\n",
    "# Convert the list of JSON objects into a DataFrame\n",
    "df_steam_games = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza y Normalizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_steam_games = df_steam_games.rename(columns={'id': 'item_id'})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_0(valor):\n",
    "    try:\n",
    "        return float(valor)\n",
    "    except (ValueError, TypeError):\n",
    "        try:\n",
    "            # Intentar convertir a entero y luego a float con decimal 0\n",
    "            return float(int(valor))\n",
    "        except (ValueError, TypeError):\n",
    "            return 0.0\n",
    "\n",
    "df_steam_games['price'] = df_steam_games['price'].apply(convert_to_0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the release year from the 'release_date' column and create a new 'release_year' column\n",
    "df_steam_games['release_year'] = df_steam_games['release_date'].str.extract(r'(\\d{4})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the specified columns from the DataFrame\n",
    "df_steam_games = df_steam_games.drop(['publisher', 'release_date', 'title', 'app_name', 'url', 'tags', 'reviews_url', 'specs', 'early_access'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de columnas a procesar\n",
    "cols = ['genres']\n",
    "\n",
    "# Itera a través de las columnas\n",
    "for i in cols:\n",
    "    # Convierte los valores de la columna en cadenas de texto\n",
    "    df_steam_games[i] = df_steam_games[i].astype(str)\n",
    "    \n",
    "    # Elimina los corchetes '[' y ']' de los valores de la columna\n",
    "    df_steam_games[i] = df_steam_games[i].str.replace('[', '').str.replace(']', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nulos y Duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where all columns are null\n",
    "df_steam_games = df_steam_games.dropna(how=\"all\")\n",
    "\n",
    "# Drop rows where the 'developer' field is NaN\n",
    "df_steam_games = df_steam_games.dropna(subset=['developer'])\n",
    "\n",
    "# Drop rows where the 'price' field is NaN\n",
    "df_steam_games = df_steam_games.dropna(subset=['price'])\n",
    "\n",
    "# Drop rows where the 'release_year' field is NaN\n",
    "df_steam_games = df_steam_games.dropna(subset=['release_year'])\n",
    "\n",
    "df_steam_games = df_steam_games.dropna(subset=['item_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_steam_games['item_id'] = df_steam_games['item_id'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    27592\n",
       "True         1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_steam_games.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_steam_games = df_steam_games.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Exportar el dataframe a parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_steam_games.to_parquet('Data/steam_games.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def developer(developer):\n",
    "    df_developer = df_steam_games[df_steam_games[\"developer\"] == developer]\n",
    "    items_per_year = df_developer.groupby(\"release_year\")[\"item_id\"].count()\n",
    "\n",
    "    # Filter the developer's DataFrame for free games (price zero):\n",
    "    df_dev_free = df_developer[df_developer[\"price\"] == 0]\n",
    "\n",
    "    # Get the number of free items per year\n",
    "    free_items = df_dev_free.groupby(\"release_year\")[\"price\"].count()  # Number of free items per year\n",
    "\n",
    "    # Calculate the percentage of free content per year\n",
    "    free_proportion = round((free_items / items_per_year) * 100, 2)\n",
    "\n",
    "    # Rename the series to merge them into a DataFrame:\n",
    "    items_per_year.name = \"Number of Items\"\n",
    "    free_proportion.name = \"Free Content\"\n",
    "\n",
    "    df1 = pd.merge(items_per_year, free_proportion, on=\"release_year\").reset_index()\n",
    "    df1 = df1.fillna(0)\n",
    "\n",
    "    df1 = df1.rename(columns={\"release_year\": \"Year\"})\n",
    "\n",
    "    # Format the Free Content column:\n",
    "    df1[\"Free Content\"] = df1[\"Free Content\"].apply(lambda x: f\"{x}%\")\n",
    "\n",
    "    # Convert the DataFrame to a dictionary\n",
    "    dictionary = df1.to_dict(orient=\"records\")\n",
    "    del df_developer, items_per_year, df_dev_free, free_items, free_proportion, df1\n",
    "    return dictionary\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews_games = df_user_reviews.merge(df_steam_games[['item_id', 'price']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def userdata(user_id):\n",
    "    # Filter the data for the specified user\n",
    "    user_data = df_reviews_games[df_reviews_games['user_id'] == user_id]\n",
    "\n",
    "    # Calculate the amount of money spent by the user\n",
    "    spent_money = user_data['price'].sum()\n",
    "\n",
    "    # Calculate the recommendation percentage based on reviews.recommend\n",
    "    recommendations = (user_data['recommend'] == True).sum()\n",
    "    recommendation_percentage = recommendations / len(user_data) * 100\n",
    "\n",
    "    # Calculate the number of items\n",
    "    number_of_items = user_data['item_id'].nunique()\n",
    "\n",
    "    # Create a dictionary with the results\n",
    "    results = {\n",
    "        'Amount of money spent': round(spent_money, 2),\n",
    "        'Recommendation Percentage': recommendation_percentage,\n",
    "        'Number of items': number_of_items\n",
    "    }\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Amount of money spent': 89.95,\n",
       " 'Recommendation Percentage': 100.0,\n",
       " 'Number of items': 5}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userdata('Wackky')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UserForGenre(genre):\n",
    "    \n",
    "    # Filter games by the specified genre\n",
    "    games_filtered = df_steam_games[df_steam_games['genres'].str.contains(genre, case=False, na=False)]\n",
    "\n",
    "    # Merge df_user_items and df_games based on item_id and id\n",
    "    merged_df = pd.merge(df_user_items, games_filtered, left_on='item_id', right_on='item_id', how='inner')\n",
    "\n",
    "    # Group by year and user, calculate the playtime by user per year\n",
    "    grouped = merged_df.groupby(['release_year', 'user_id'])['playtime_forever'].sum().reset_index()\n",
    "\n",
    "    if len(grouped) > 0:\n",
    "        # Find the user with the most playtime for the given genre\n",
    "        max_user = grouped[grouped['playtime_forever'] == grouped.groupby('release_year')['playtime_forever'].transform('max')]['user_id'].values[0]\n",
    "    else:\n",
    "        return {\"error\": \"No data available for the specified genre\"}\n",
    "\n",
    "    # Filter the data for the user with the most playtime\n",
    "    user_data = grouped[grouped['user_id'] == max_user]\n",
    "\n",
    "    # Remove years with 0 playtime\n",
    "    user_data = user_data[user_data['playtime_forever'] > 0]\n",
    "\n",
    "    # Sort years in descending order\n",
    "    user_data = user_data.sort_values(by='release_year', ascending=False)\n",
    "\n",
    "    # Convert playtime to integers\n",
    "    user_data['playtime_forever'] = user_data['playtime_forever'].astype(int)\n",
    "\n",
    "    # Create a list of accumulated playtime by year\n",
    "    hours_by_year = [{'Year': int(year), 'Hours': int(hours)} for year, hours in zip(user_data['release_year'], user_data['playtime_forever'])]\n",
    "\n",
    "    result = {\n",
    "        \"User with the Most Playtime for Genre \" + genre: max_user,\n",
    "        \"Playtime\": hours_by_year\n",
    "    }\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fourth Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_games_reviews = pd.merge(df_steam_games, df_user_reviews, how=\"inner\", left_on=\"item_id\", right_on=\"item_id\")\n",
    "df_games_reviews = df_games_reviews.drop(['price', 'item_id', 'release_year', 'user_id', 'item_id', 'sentiment_analysis'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_developer_year(year):\n",
    "    df = df_games_reviews\n",
    "    \n",
    "    # Convert columns to the appropriate data types\n",
    "    df[\"recommend\"] = df[\"recommend\"].astype(int)\n",
    "    df[\"year\"] = df[\"year\"].astype(int)\n",
    "    \n",
    "    # Perform groupby and apply an aggregation function\n",
    "    df = df.groupby(['developer', 'year'])['recommend'].sum().reset_index()\n",
    "\n",
    "    # Rename the resulting column\n",
    "    df = df.rename(columns={'recommend': 'total_true'})\n",
    "    \n",
    "    # Filter the data for the specified year\n",
    "    filtered_df = df[df['year'] == year]\n",
    "    if filtered_df.empty:\n",
    "        return \"No data found for that year\"\n",
    "\n",
    "    # Group by developer and sum recommended games\n",
    "    developer_grouped = filtered_df.groupby('developer')['total_true'].sum().reset_index()\n",
    "\n",
    "    # Sort in descending order\n",
    "    developer_grouped = developer_grouped.sort_values(by='total_true', ascending=False)\n",
    "\n",
    "    # Add the position rank\n",
    "    developer_grouped['Position'] = range(1, len(developer_grouped) + 1)\n",
    "\n",
    "    # Select the top 3 developers\n",
    "    top_developers = developer_grouped.head(3)\n",
    "\n",
    "    # Create the result in the desired format\n",
    "    result = [{\"Position {}: {}\".format(row['Position'], row['developer']): row['total_true']} for i, row in top_developers.iterrows()]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fifth Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_games_reviews = pd.merge(df_steam_games, df_user_reviews, how=\"inner\", left_on=\"item_id\", right_on=\"item_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def developer_reviews_analysis(developer):\n",
    "    df = df_games_reviews\n",
    "    df = df.drop(['item_id', 'release_year', 'price'], axis= 1)\n",
    "    # Filtramos las reseñas del desarrollador especificado\n",
    "    df = df[df[\"developer\"] == developer]\n",
    "\n",
    "    # Contamos el número de reseñas positivas y negativas\n",
    "    count_positive = df[df[\"sentiment_analysis\"] == 2].shape[0]\n",
    "    count_negative = df[df[\"sentiment_analysis\"] == 0].shape[0]\n",
    "\n",
    "    # Devolvemos el resultado\n",
    "    return {\n",
    "        \"developer\": developer,\n",
    "        \"negative\": count_negative,\n",
    "        \"positive\": count_positive,\n",
    "    }\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
